{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCJZj762yLOc",
        "outputId": "2b683bce-aef5-428b-c694-dbe580897030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 298ms/step - loss: 131.5501 - mean_absolute_error: 11.2099 - val_loss: 103.1148 - val_mean_absolute_error: 9.9890\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 118.0822 - mean_absolute_error: 10.5858 - val_loss: 93.6084 - val_mean_absolute_error: 9.4953\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 105.2794 - mean_absolute_error: 9.9532 - val_loss: 83.7588 - val_mean_absolute_error: 8.9536\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 92.6996 - mean_absolute_error: 9.2827 - val_loss: 73.6543 - val_mean_absolute_error: 8.3567\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 79.6469 - mean_absolute_error: 8.5518 - val_loss: 63.5611 - val_mean_absolute_error: 7.7077\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 67.0061 - mean_absolute_error: 7.7566 - val_loss: 53.3037 - val_mean_absolute_error: 6.9801\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 53.8606 - mean_absolute_error: 6.8419 - val_loss: 43.1608 - val_mean_absolute_error: 6.1687\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 41.7530 - mean_absolute_error: 5.8713 - val_loss: 33.5337 - val_mean_absolute_error: 5.2829\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 29.9865 - mean_absolute_error: 4.9191 - val_loss: 24.8366 - val_mean_absolute_error: 4.4603\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 20.0498 - mean_absolute_error: 3.8701 - val_loss: 17.4886 - val_mean_absolute_error: 3.5729\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 12.3974 - mean_absolute_error: 2.8729 - val_loss: 12.0048 - val_mean_absolute_error: 2.8061\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 8.7887 - mean_absolute_error: 2.2754 - val_loss: 8.7884 - val_mean_absolute_error: 2.4173\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 7.7619 - mean_absolute_error: 2.0832 - val_loss: 7.5376 - val_mean_absolute_error: 2.2619\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 8.6499 - mean_absolute_error: 2.2963 - val_loss: 7.2826 - val_mean_absolute_error: 2.1891\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 9.0775 - mean_absolute_error: 2.4964 - val_loss: 7.0888 - val_mean_absolute_error: 2.2186\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 8.0902 - mean_absolute_error: 2.4306 - val_loss: 6.6899 - val_mean_absolute_error: 2.2145\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 6.0591 - mean_absolute_error: 2.1194 - val_loss: 6.3557 - val_mean_absolute_error: 2.1875\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 3.6960 - mean_absolute_error: 1.6238 - val_loss: 6.3892 - val_mean_absolute_error: 2.1781\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 2.0067 - mean_absolute_error: 1.1218 - val_loss: 6.7878 - val_mean_absolute_error: 2.1846\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.2583 - mean_absolute_error: 0.8444 - val_loss: 7.3965 - val_mean_absolute_error: 2.1864\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 1.1352 - mean_absolute_error: 0.8136 - val_loss: 8.0294 - val_mean_absolute_error: 2.2058\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.3241 - mean_absolute_error: 0.9251 - val_loss: 8.5234 - val_mean_absolute_error: 2.2570\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.4726 - mean_absolute_error: 1.0050 - val_loss: 8.7715 - val_mean_absolute_error: 2.3004\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1.5295 - mean_absolute_error: 1.0428 - val_loss: 8.7792 - val_mean_absolute_error: 2.3167\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.3836 - mean_absolute_error: 0.9890 - val_loss: 8.5958 - val_mean_absolute_error: 2.3105\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1.1204 - mean_absolute_error: 0.8715 - val_loss: 8.2788 - val_mean_absolute_error: 2.2955\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.8103 - mean_absolute_error: 0.7166 - val_loss: 7.9444 - val_mean_absolute_error: 2.2885\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.5590 - mean_absolute_error: 0.5641 - val_loss: 7.6420 - val_mean_absolute_error: 2.2776\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4311 - mean_absolute_error: 0.4821 - val_loss: 7.4153 - val_mean_absolute_error: 2.2661\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3945 - mean_absolute_error: 0.4735 - val_loss: 7.2560 - val_mean_absolute_error: 2.2551\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3946 - mean_absolute_error: 0.4833 - val_loss: 7.1654 - val_mean_absolute_error: 2.2462\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3871 - mean_absolute_error: 0.4947 - val_loss: 7.1291 - val_mean_absolute_error: 2.2408\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3435 - mean_absolute_error: 0.4672 - val_loss: 7.1415 - val_mean_absolute_error: 2.2388\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2900 - mean_absolute_error: 0.4159 - val_loss: 7.1994 - val_mean_absolute_error: 2.2391\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2209 - mean_absolute_error: 0.3420 - val_loss: 7.2883 - val_mean_absolute_error: 2.2414\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1755 - mean_absolute_error: 0.2698 - val_loss: 7.3933 - val_mean_absolute_error: 2.2445\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1509 - mean_absolute_error: 0.2167 - val_loss: 7.4930 - val_mean_absolute_error: 2.2482\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1467 - mean_absolute_error: 0.2115 - val_loss: 7.5654 - val_mean_absolute_error: 2.2510\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1404 - mean_absolute_error: 0.2150 - val_loss: 7.6024 - val_mean_absolute_error: 2.2529\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1328 - mean_absolute_error: 0.2178 - val_loss: 7.6021 - val_mean_absolute_error: 2.2538\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1234 - mean_absolute_error: 0.2078 - val_loss: 7.5686 - val_mean_absolute_error: 2.2537\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1043 - mean_absolute_error: 0.1842 - val_loss: 7.5208 - val_mean_absolute_error: 2.2530\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0833 - mean_absolute_error: 0.1535 - val_loss: 7.4752 - val_mean_absolute_error: 2.2520\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0734 - mean_absolute_error: 0.1382 - val_loss: 7.4372 - val_mean_absolute_error: 2.2512\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0697 - mean_absolute_error: 0.1381 - val_loss: 7.4115 - val_mean_absolute_error: 2.2508\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0683 - mean_absolute_error: 0.1387 - val_loss: 7.4017 - val_mean_absolute_error: 2.2511\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0678 - mean_absolute_error: 0.1420 - val_loss: 7.4085 - val_mean_absolute_error: 2.2524\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0627 - mean_absolute_error: 0.1347 - val_loss: 7.4254 - val_mean_absolute_error: 2.2541\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0564 - mean_absolute_error: 0.1202 - val_loss: 7.4522 - val_mean_absolute_error: 2.2558\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0506 - mean_absolute_error: 0.1040 - val_loss: 7.4798 - val_mean_absolute_error: 2.2575\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0460 - mean_absolute_error: 0.1003 - val_loss: 7.5047 - val_mean_absolute_error: 2.2589\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0438 - mean_absolute_error: 0.0996 - val_loss: 7.5229 - val_mean_absolute_error: 2.2597\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0416 - mean_absolute_error: 0.1043 - val_loss: 7.5312 - val_mean_absolute_error: 2.2602\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0405 - mean_absolute_error: 0.1047 - val_loss: 7.5320 - val_mean_absolute_error: 2.2603\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0377 - mean_absolute_error: 0.0983 - val_loss: 7.5226 - val_mean_absolute_error: 2.2602\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0347 - mean_absolute_error: 0.0881 - val_loss: 7.5084 - val_mean_absolute_error: 2.2600\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0323 - mean_absolute_error: 0.0789 - val_loss: 7.4940 - val_mean_absolute_error: 2.2595\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0298 - mean_absolute_error: 0.0748 - val_loss: 7.4814 - val_mean_absolute_error: 2.2593\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0285 - mean_absolute_error: 0.0741 - val_loss: 7.4739 - val_mean_absolute_error: 2.2593\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0276 - mean_absolute_error: 0.0750 - val_loss: 7.4705 - val_mean_absolute_error: 2.2598\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0262 - mean_absolute_error: 0.0742 - val_loss: 7.4714 - val_mean_absolute_error: 2.2604\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0243 - mean_absolute_error: 0.0700 - val_loss: 7.4762 - val_mean_absolute_error: 2.2612\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0233 - mean_absolute_error: 0.0644 - val_loss: 7.4835 - val_mean_absolute_error: 2.2621\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0220 - mean_absolute_error: 0.0580 - val_loss: 7.4914 - val_mean_absolute_error: 2.2627\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0209 - mean_absolute_error: 0.0559 - val_loss: 7.4953 - val_mean_absolute_error: 2.2633\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0199 - mean_absolute_error: 0.0556 - val_loss: 7.4974 - val_mean_absolute_error: 2.2636\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0190 - mean_absolute_error: 0.0552 - val_loss: 7.4949 - val_mean_absolute_error: 2.2636\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0184 - mean_absolute_error: 0.0538 - val_loss: 7.4892 - val_mean_absolute_error: 2.2634\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0171 - mean_absolute_error: 0.0509 - val_loss: 7.4831 - val_mean_absolute_error: 2.2630\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0167 - mean_absolute_error: 0.0486 - val_loss: 7.4747 - val_mean_absolute_error: 2.2626\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0160 - mean_absolute_error: 0.0470 - val_loss: 7.4683 - val_mean_absolute_error: 2.2620\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0152 - mean_absolute_error: 0.0456 - val_loss: 7.4620 - val_mean_absolute_error: 2.2617\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0145 - mean_absolute_error: 0.0447 - val_loss: 7.4572 - val_mean_absolute_error: 2.2613\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0139 - mean_absolute_error: 0.0438 - val_loss: 7.4540 - val_mean_absolute_error: 2.2610\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0132 - mean_absolute_error: 0.0426 - val_loss: 7.4513 - val_mean_absolute_error: 2.2609\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0130 - mean_absolute_error: 0.0418 - val_loss: 7.4501 - val_mean_absolute_error: 2.2607\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0123 - mean_absolute_error: 0.0402 - val_loss: 7.4489 - val_mean_absolute_error: 2.2607\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0119 - mean_absolute_error: 0.0388 - val_loss: 7.4479 - val_mean_absolute_error: 2.2607\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0113 - mean_absolute_error: 0.0374 - val_loss: 7.4459 - val_mean_absolute_error: 2.2607\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0109 - mean_absolute_error: 0.0365 - val_loss: 7.4442 - val_mean_absolute_error: 2.2607\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0103 - mean_absolute_error: 0.0355 - val_loss: 7.4422 - val_mean_absolute_error: 2.2607\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0100 - mean_absolute_error: 0.0346 - val_loss: 7.4397 - val_mean_absolute_error: 2.2608\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0097 - mean_absolute_error: 0.0339 - val_loss: 7.4378 - val_mean_absolute_error: 2.2608\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0094 - mean_absolute_error: 0.0332 - val_loss: 7.4360 - val_mean_absolute_error: 2.2608\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0090 - mean_absolute_error: 0.0324 - val_loss: 7.4337 - val_mean_absolute_error: 2.2608\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0086 - mean_absolute_error: 0.0315 - val_loss: 7.4319 - val_mean_absolute_error: 2.2607\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0083 - mean_absolute_error: 0.0306 - val_loss: 7.4298 - val_mean_absolute_error: 2.2607\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0081 - mean_absolute_error: 0.0299 - val_loss: 7.4293 - val_mean_absolute_error: 2.2605\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0077 - mean_absolute_error: 0.0292 - val_loss: 7.4275 - val_mean_absolute_error: 2.2603\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0073 - mean_absolute_error: 0.0285 - val_loss: 7.4252 - val_mean_absolute_error: 2.2602\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0071 - mean_absolute_error: 0.0279 - val_loss: 7.4228 - val_mean_absolute_error: 2.2600\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - mean_absolute_error: 0.0274 - val_loss: 7.4204 - val_mean_absolute_error: 2.2598\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0067 - mean_absolute_error: 0.0272 - val_loss: 7.4167 - val_mean_absolute_error: 2.2598\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0062 - mean_absolute_error: 0.0261 - val_loss: 7.4150 - val_mean_absolute_error: 2.2596\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0060 - mean_absolute_error: 0.0255 - val_loss: 7.4141 - val_mean_absolute_error: 2.2595\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0058 - mean_absolute_error: 0.0247 - val_loss: 7.4129 - val_mean_absolute_error: 2.2594\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0056 - mean_absolute_error: 0.0242 - val_loss: 7.4115 - val_mean_absolute_error: 2.2594\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0053 - mean_absolute_error: 0.0235 - val_loss: 7.4115 - val_mean_absolute_error: 2.2593\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0052 - mean_absolute_error: 0.0231 - val_loss: 7.4112 - val_mean_absolute_error: 2.2592\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0049 - mean_absolute_error: 0.0227 - val_loss: 7.4097 - val_mean_absolute_error: 2.2591\n",
            "Test Loss: 6.813905239105225, Test MAE: 2.051238536834717\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/mini1.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Function to split comma-separated values and flatten the DataFrame\n",
        "def split_and_flatten(df, columns):\n",
        "    for col in columns:\n",
        "        # Split the column into separate features\n",
        "        split_cols = df[col].str.split(',', expand=True)\n",
        "        split_cols = split_cols.rename(columns=lambda x: f\"{col}_{x+1}\")\n",
        "        # Concatenate the new columns to the original DataFrame\n",
        "        df = pd.concat([df, split_cols], axis=1)\n",
        "        df.drop(col, axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# Columns to split\n",
        "columns_to_split = ['A', 'B', 'C', 'DR', 'A.1', 'B.1', 'C.1', 'DR.1']\n",
        "\n",
        "# Split and flatten the DataFrame\n",
        "data = split_and_flatten(data, columns_to_split)\n",
        "\n",
        "# Identify columns with categorical values\n",
        "categorical_columns = [col for col in data.columns if data[col].dtype == 'object' and col != 'SURVIVAL']\n",
        "\n",
        "# Apply one-hot encoding to categorical columns\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "encoded_data = encoder.fit_transform(data[categorical_columns])\n",
        "\n",
        "# Convert encoded data to DataFrame\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "# Drop original categorical columns and concatenate the encoded columns\n",
        "data.drop(categorical_columns, axis=1, inplace=True)\n",
        "data = pd.concat([data, encoded_df], axis=1)\n",
        "\n",
        "# Normalize the numerical columns\n",
        "numerical_columns = [col for col in data.columns if col not in ['SURVIVAL', 'MLC']]\n",
        "data[numerical_columns] = data[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
        "data[numerical_columns] = (data[numerical_columns] - data[numerical_columns].mean()) / data[numerical_columns].std()\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(['SURVIVAL'], axis=1)\n",
        "y = data['SURVIVAL']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/mini1.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Function to split comma-separated values and flatten the DataFrame\n",
        "def split_and_flatten(df, columns):\n",
        "    for col in columns:\n",
        "        # Split the column into separate features\n",
        "        split_cols = df[col].str.split(',', expand=True)\n",
        "        split_cols = split_cols.rename(columns=lambda x: f\"{col}_{x+1}\")\n",
        "        # Concatenate the new columns to the original DataFrame\n",
        "        df = pd.concat([df, split_cols], axis=1)\n",
        "        df.drop(col, axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# Columns to split\n",
        "columns_to_split = ['A', 'B', 'C', 'DR', 'A.1', 'B.1', 'C.1', 'DR.1']\n",
        "\n",
        "# Split and flatten the DataFrame\n",
        "data = split_and_flatten(data, columns_to_split)\n",
        "\n",
        "# Identify columns with categorical values\n",
        "categorical_columns = [col for col in data.columns if data[col].dtype == 'object' and col != 'SURVIVAL']\n",
        "\n",
        "# Apply one-hot encoding to categorical columns\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "encoded_data = encoder.fit_transform(data[categorical_columns])\n",
        "\n",
        "# Convert encoded data to DataFrame\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "# Drop original categorical columns and concatenate the encoded columns\n",
        "data.drop(categorical_columns, axis=1, inplace=True)\n",
        "data = pd.concat([data, encoded_df], axis=1)\n",
        "\n",
        "# Normalize the numerical columns\n",
        "numerical_columns = [col for col in data.columns if col not in ['SURVIVAL', 'MLC']]\n",
        "data[numerical_columns] = data[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
        "data[numerical_columns] = (data[numerical_columns] - data[numerical_columns].mean()) / data[numerical_columns].std()\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(['SURVIVAL'], axis=1)\n",
        "y = data['SURVIVAL']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
        "\n",
        "# Function to preprocess a single input for prediction\n",
        "def preprocess_input(input_data, encoder, numerical_columns, categorical_columns):\n",
        "    # Create a DataFrame for the input data\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "\n",
        "    # Split and flatten the DataFrame\n",
        "    input_df = split_and_flatten(input_df, columns_to_split)\n",
        "\n",
        "    # Apply one-hot encoding to categorical columns\n",
        "    encoded_input_data = encoder.transform(input_df[categorical_columns])\n",
        "    encoded_input_df = pd.DataFrame(encoded_input_data, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "    # Drop original categorical columns and concatenate the encoded columns\n",
        "    input_df.drop(categorical_columns, axis=1, inplace=True)\n",
        "    input_df = pd.concat([input_df, encoded_input_df], axis=1)\n",
        "\n",
        "    # Normalize the numerical columns\n",
        "    input_df[numerical_columns] = input_df[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
        "    input_df[numerical_columns] = (input_df[numerical_columns] - data[numerical_columns].mean()) / data[numerical_columns].std()\n",
        "\n",
        "    return input_df\n",
        "\n",
        "# Example input data\n",
        "example_input = {\n",
        "    'A': '3,9',\n",
        "    'B': '7,40',\n",
        "    'C': 'w3,-',\n",
        "    'DR': 'w2,-',\n",
        "    'A.1': '1,3',\n",
        "    'B.1': '7,8',\n",
        "    'C.1': 'w1,w1',\n",
        "    'DR.1': 'w2,w3',\n",
        "    'MLC': 0\n",
        "}\n",
        "\n",
        "# Preprocess the input data\n",
        "preprocessed_input = preprocess_input(example_input, encoder, numerical_columns, categorical_columns)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(preprocessed_input)\n",
        "\n",
        "print(f\"Predicted Survival: {prediction[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mVopqUFy57B",
        "outputId": "39acb61b-8f05-455f-84e9-1cc697d10428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 150.3745 - mean_absolute_error: 12.0193 - val_loss: 119.2152 - val_mean_absolute_error: 10.7386\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 137.1249 - mean_absolute_error: 11.4454 - val_loss: 108.3713 - val_mean_absolute_error: 10.2192\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 124.8994 - mean_absolute_error: 10.8964 - val_loss: 97.9638 - val_mean_absolute_error: 9.6957\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 113.3701 - mean_absolute_error: 10.3448 - val_loss: 87.6661 - val_mean_absolute_error: 9.1516\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 102.1821 - mean_absolute_error: 9.7760 - val_loss: 77.5093 - val_mean_absolute_error: 8.5750\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 90.3345 - mean_absolute_error: 9.1329 - val_loss: 67.1439 - val_mean_absolute_error: 7.9376\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 78.1964 - mean_absolute_error: 8.4361 - val_loss: 56.6483 - val_mean_absolute_error: 7.2330\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 65.6735 - mean_absolute_error: 7.6574 - val_loss: 46.2420 - val_mean_absolute_error: 6.4543\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 53.5784 - mean_absolute_error: 6.8193 - val_loss: 36.2320 - val_mean_absolute_error: 5.5948\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 41.4708 - mean_absolute_error: 5.8933 - val_loss: 27.1824 - val_mean_absolute_error: 4.6940\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 30.9768 - mean_absolute_error: 4.8606 - val_loss: 19.2078 - val_mean_absolute_error: 3.8522\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 21.1061 - mean_absolute_error: 3.8134 - val_loss: 12.9887 - val_mean_absolute_error: 3.0688\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 13.9530 - mean_absolute_error: 2.9051 - val_loss: 8.7178 - val_mean_absolute_error: 2.2889\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 9.1615 - mean_absolute_error: 2.2298 - val_loss: 6.5537 - val_mean_absolute_error: 1.8811\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 7.5099 - mean_absolute_error: 2.0008 - val_loss: 6.1534 - val_mean_absolute_error: 1.9098\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 7.6671 - mean_absolute_error: 2.1310 - val_loss: 6.7184 - val_mean_absolute_error: 2.0906\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 8.1811 - mean_absolute_error: 2.2662 - val_loss: 7.2320 - val_mean_absolute_error: 2.1898\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 7.9562 - mean_absolute_error: 2.4097 - val_loss: 7.2392 - val_mean_absolute_error: 2.2046\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 6.8295 - mean_absolute_error: 2.2932 - val_loss: 6.6944 - val_mean_absolute_error: 2.0845\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 5.0420 - mean_absolute_error: 1.9702 - val_loss: 5.9701 - val_mean_absolute_error: 1.8870\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.0800 - mean_absolute_error: 1.5003 - val_loss: 5.3759 - val_mean_absolute_error: 1.7157\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.8795 - mean_absolute_error: 1.0808 - val_loss: 5.0695 - val_mean_absolute_error: 1.6351\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.2643 - mean_absolute_error: 0.8288 - val_loss: 5.0157 - val_mean_absolute_error: 1.5852\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.0857 - mean_absolute_error: 0.7948 - val_loss: 5.1403 - val_mean_absolute_error: 1.5641\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.1611 - mean_absolute_error: 0.8438 - val_loss: 5.3101 - val_mean_absolute_error: 1.5467\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 1.2718 - mean_absolute_error: 0.8975 - val_loss: 5.4309 - val_mean_absolute_error: 1.5490\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.3106 - mean_absolute_error: 0.9049 - val_loss: 5.4723 - val_mean_absolute_error: 1.5501\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.1981 - mean_absolute_error: 0.8659 - val_loss: 5.4321 - val_mean_absolute_error: 1.5359\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.9784 - mean_absolute_error: 0.7870 - val_loss: 5.3511 - val_mean_absolute_error: 1.5268\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.7489 - mean_absolute_error: 0.6774 - val_loss: 5.2742 - val_mean_absolute_error: 1.5223\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.5206 - mean_absolute_error: 0.5514 - val_loss: 5.2314 - val_mean_absolute_error: 1.5332\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3776 - mean_absolute_error: 0.4437 - val_loss: 5.2269 - val_mean_absolute_error: 1.5545\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.3213 - mean_absolute_error: 0.3939 - val_loss: 5.2550 - val_mean_absolute_error: 1.5721\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.3047 - mean_absolute_error: 0.3939 - val_loss: 5.2862 - val_mean_absolute_error: 1.5894\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3119 - mean_absolute_error: 0.4152 - val_loss: 5.3039 - val_mean_absolute_error: 1.5926\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.3007 - mean_absolute_error: 0.4181 - val_loss: 5.3061 - val_mean_absolute_error: 1.5846\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2665 - mean_absolute_error: 0.3931 - val_loss: 5.2994 - val_mean_absolute_error: 1.5682\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.2237 - mean_absolute_error: 0.3443 - val_loss: 5.2934 - val_mean_absolute_error: 1.5447\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1788 - mean_absolute_error: 0.2798 - val_loss: 5.3015 - val_mean_absolute_error: 1.5340\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1458 - mean_absolute_error: 0.2282 - val_loss: 5.3259 - val_mean_absolute_error: 1.5306\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1278 - mean_absolute_error: 0.1891 - val_loss: 5.3560 - val_mean_absolute_error: 1.5279\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.1226 - mean_absolute_error: 0.1703 - val_loss: 5.3883 - val_mean_absolute_error: 1.5259\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1227 - mean_absolute_error: 0.1786 - val_loss: 5.4145 - val_mean_absolute_error: 1.5249\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.1160 - mean_absolute_error: 0.1810 - val_loss: 5.4350 - val_mean_absolute_error: 1.5262\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1033 - mean_absolute_error: 0.1740 - val_loss: 5.4475 - val_mean_absolute_error: 1.5277\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0910 - mean_absolute_error: 0.1586 - val_loss: 5.4573 - val_mean_absolute_error: 1.5306\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0846 - mean_absolute_error: 0.1404 - val_loss: 5.4639 - val_mean_absolute_error: 1.5330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0753 - mean_absolute_error: 0.1263 - val_loss: 5.4701 - val_mean_absolute_error: 1.5404\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0707 - mean_absolute_error: 0.1220 - val_loss: 5.4759 - val_mean_absolute_error: 1.5475\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0652 - mean_absolute_error: 0.1229 - val_loss: 5.4783 - val_mean_absolute_error: 1.5510\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0642 - mean_absolute_error: 0.1237 - val_loss: 5.4776 - val_mean_absolute_error: 1.5514\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0603 - mean_absolute_error: 0.1187 - val_loss: 5.4726 - val_mean_absolute_error: 1.5484\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0558 - mean_absolute_error: 0.1101 - val_loss: 5.4660 - val_mean_absolute_error: 1.5440\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0520 - mean_absolute_error: 0.0988 - val_loss: 5.4588 - val_mean_absolute_error: 1.5428\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0463 - mean_absolute_error: 0.0876 - val_loss: 5.4517 - val_mean_absolute_error: 1.5421\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0444 - mean_absolute_error: 0.0843 - val_loss: 5.4454 - val_mean_absolute_error: 1.5419\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0412 - mean_absolute_error: 0.0819 - val_loss: 5.4392 - val_mean_absolute_error: 1.5411\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0393 - mean_absolute_error: 0.0801 - val_loss: 5.4340 - val_mean_absolute_error: 1.5406\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0381 - mean_absolute_error: 0.0779 - val_loss: 5.4298 - val_mean_absolute_error: 1.5406\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0364 - mean_absolute_error: 0.0746 - val_loss: 5.4262 - val_mean_absolute_error: 1.5403\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0336 - mean_absolute_error: 0.0703 - val_loss: 5.4239 - val_mean_absolute_error: 1.5406\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0314 - mean_absolute_error: 0.0673 - val_loss: 5.4221 - val_mean_absolute_error: 1.5405\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0297 - mean_absolute_error: 0.0648 - val_loss: 5.4211 - val_mean_absolute_error: 1.5404\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0289 - mean_absolute_error: 0.0639 - val_loss: 5.4213 - val_mean_absolute_error: 1.5406\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0271 - mean_absolute_error: 0.0623 - val_loss: 5.4218 - val_mean_absolute_error: 1.5408\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0258 - mean_absolute_error: 0.0603 - val_loss: 5.4219 - val_mean_absolute_error: 1.5408\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0244 - mean_absolute_error: 0.0583 - val_loss: 5.4217 - val_mean_absolute_error: 1.5403\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0234 - mean_absolute_error: 0.0555 - val_loss: 5.4215 - val_mean_absolute_error: 1.5403\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0224 - mean_absolute_error: 0.0533 - val_loss: 5.4216 - val_mean_absolute_error: 1.5401\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0214 - mean_absolute_error: 0.0514 - val_loss: 5.4214 - val_mean_absolute_error: 1.5403\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0203 - mean_absolute_error: 0.0498 - val_loss: 5.4206 - val_mean_absolute_error: 1.5406\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0191 - mean_absolute_error: 0.0485 - val_loss: 5.4199 - val_mean_absolute_error: 1.5406\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0182 - mean_absolute_error: 0.0475 - val_loss: 5.4193 - val_mean_absolute_error: 1.5409\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0177 - mean_absolute_error: 0.0464 - val_loss: 5.4183 - val_mean_absolute_error: 1.5415\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0170 - mean_absolute_error: 0.0449 - val_loss: 5.4175 - val_mean_absolute_error: 1.5424\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0160 - mean_absolute_error: 0.0432 - val_loss: 5.4164 - val_mean_absolute_error: 1.5432\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0152 - mean_absolute_error: 0.0420 - val_loss: 5.4154 - val_mean_absolute_error: 1.5442\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0150 - mean_absolute_error: 0.0419 - val_loss: 5.4142 - val_mean_absolute_error: 1.5449\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0141 - mean_absolute_error: 0.0410 - val_loss: 5.4133 - val_mean_absolute_error: 1.5456\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0136 - mean_absolute_error: 0.0402 - val_loss: 5.4120 - val_mean_absolute_error: 1.5463\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0128 - mean_absolute_error: 0.0386 - val_loss: 5.4107 - val_mean_absolute_error: 1.5466\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0126 - mean_absolute_error: 0.0377 - val_loss: 5.4102 - val_mean_absolute_error: 1.5472\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0119 - mean_absolute_error: 0.0364 - val_loss: 5.4093 - val_mean_absolute_error: 1.5474\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0115 - mean_absolute_error: 0.0353 - val_loss: 5.4088 - val_mean_absolute_error: 1.5476\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0110 - mean_absolute_error: 0.0343 - val_loss: 5.4084 - val_mean_absolute_error: 1.5477\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0105 - mean_absolute_error: 0.0336 - val_loss: 5.4080 - val_mean_absolute_error: 1.5478\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0101 - mean_absolute_error: 0.0328 - val_loss: 5.4074 - val_mean_absolute_error: 1.5480\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0099 - mean_absolute_error: 0.0325 - val_loss: 5.4069 - val_mean_absolute_error: 1.5485\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0095 - mean_absolute_error: 0.0319 - val_loss: 5.4063 - val_mean_absolute_error: 1.5486\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0092 - mean_absolute_error: 0.0315 - val_loss: 5.4052 - val_mean_absolute_error: 1.5486\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0088 - mean_absolute_error: 0.0307 - val_loss: 5.4044 - val_mean_absolute_error: 1.5491\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0085 - mean_absolute_error: 0.0301 - val_loss: 5.4033 - val_mean_absolute_error: 1.5496\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0081 - mean_absolute_error: 0.0291 - val_loss: 5.4020 - val_mean_absolute_error: 1.5497\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0078 - mean_absolute_error: 0.0285 - val_loss: 5.4009 - val_mean_absolute_error: 1.5499\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0075 - mean_absolute_error: 0.0279 - val_loss: 5.3995 - val_mean_absolute_error: 1.5501\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0072 - mean_absolute_error: 0.0273 - val_loss: 5.3983 - val_mean_absolute_error: 1.5504\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0070 - mean_absolute_error: 0.0268 - val_loss: 5.3969 - val_mean_absolute_error: 1.5504\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0067 - mean_absolute_error: 0.0263 - val_loss: 5.3956 - val_mean_absolute_error: 1.5506\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0064 - mean_absolute_error: 0.0256 - val_loss: 5.3943 - val_mean_absolute_error: 1.5508\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0061 - mean_absolute_error: 0.0249 - val_loss: 5.3935 - val_mean_absolute_error: 1.5509\n",
            "Test Loss: 7.962737083435059, Test MAE: 2.1662163734436035\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Predicted Survival: 5.162730693817139\n"
          ]
        }
      ]
    }
  ]
}